---
layout: post
title: "Design of Loss Function"
date: 2024-10-08
category: [In-depth exploration]
---

# 손실 함수의 종류 및 커스텀 Loss Function

## 평균 제곱 오차 MSE(Mean Squared Error)

MSE는 회귀 문제에서 자주 사용되는 손실함수. 예측값과 실제값의 차이를 제곱한 후, 그 평균을 구한다. 평균 제곱 오차의 값이 작을수록 모델의 예측이 실제값에 가까운 것을 의미한다. 다시 말해, MSE 값이 작을수록 알고리즘의 성능이 좋다고 볼 수 있다.

<img src='/public/img/241008/MSE.png' alt='Equation of MSE'>

- MSE는 오류를 제곱하기 때문에 큰 오류에 더 민감하게 반응하여 큰 오차를 줄이는 데 유리하다.
- 그래프로 표현해 본다고 가정하면, MSE는 오차가 커질수록 손실 함수 값이 빠르게 증가하는 특징을 가지고 있다.
  - 손실 함수의 크기는 오차의 제곱에 비례하여 변한다.
  - 미분값이 일정하지 않고 오차가 커질수록 미분값도 커진다.

## 교차 엔트로피 손실 Cross-Entropy Loss

교차 엔트로피 손실은 주로 분류 문제에서 사용된다. 이진 분류나 다중 클래스 분류에서 사용되며, 모델이 예측한 확률 분포와 실제 레이블 간의 차이를 계산한다.

아래의 수식은 이진 분류의 경우의 수식을 의미한다.

<img src='/public/img/241008/Cross-Entropy Loss.png' alt='Equation of Cross-Entropy Loss'>

예측확률과 실제 레이블을 가지고 계산을 하며, 크로스 엔트로피 손실함수는 모델이 실제 레이블에 대해 높은 확률을 예측할수록 값이 작아진다.

## Custom Loss Function

<a href='https://www.ine.pt/revstat/pdf/rs070102.pdf'>"Some Thoughts about the design of Loss Function"</a>이라는 제목의 논문에 "there is no need to stick to "standard" loss function such as the L2-loss"라는 문장이 있었다. 우리가 앞으로의 프로젝트나 모델을 사용한 연구 등을 진행할 때에 기존에 배운 손실 함수들 말고도 직접 커스텀하여 손실 함수를 정의할 수 있다는 내용이다.

연구 목적이나 특정 문제에 맞게 커스텀 손실 함수를 설계할 때, 데이터의 특성이나 특정한 모델 성능을 더 강화하기 위해 맞춤형 손실 함수를 정의할 수 있다. 커스텀 손실 함수가 필요한 경우는 아래와 같다:

- 특정 목적을 강화할 때:
  - 모델을 사용할 때 소수의 오차에 아주 민감해야 하는 경우, scaling을 통해 작은 오차에 더 집중할 수 있도록 커스텀할 수 있다.
- 비대칭적 데이터를 사용할 때:
  - 양성이나 음성 데이터 비율이 크게 다른 경우에서 특정 클래스의 오차를 더 중요하게 다룰 때, 특정 클래스의 오차에 집중할 수 있도록 직접 커스텀 가능하다.
- 멀티태스크 학습:
  - 여러 가지 다른 작업을 동시에 학습할 때, 각 작업마다 다른 손실 함수를 적용하여 학습이 이루어져야 할 필요성이 있다면 여러가지의 손실 함수를 합쳐 새로운 손실 함수를 정의할 수 있다.

### 커스텀 손실 함수 설계 방법

- 기본적으로 예측값과 실제값의 차이를 수학적으로 표현하는데, 그 개념에서 벗어나지 않고 커스텀을 진행하면 된다. 예를 들어, **예측값과 실제값의 차이에 특정 가중치를 부여**하거나, 오차의 유형별로 다르게 처리할 수 있다.

## 💡Task에 맞는 Loss Function이 중요한 이유

손실함수는 기계학습 모델의 학습과정에서 중요한 역할을 하며, 손실함수를 통해 모델의 최적화를 진행할 수 있다. 또한, task에 맞는 손실 함수를 선택하는 것이 중요하다. 그 이유에 대해 알아보자.

### 학습과정에 직접적인 영향을 미친다.

손실 함수는 모델이 예측한 결과와 실제 값의 차이를 수치적으로 계산하여, 이 값을 최소화하는 방향으로 모델이 학습된다. 즉, **손실 함수가 모델의 학습 방향을 결정하는 역할을 하기 때문에, 적절하지 않은 손실 함수를 선택할 경우 모델이 잘못된 방향으로 학습될 수 있다.** 뿐만 아니라, 각 task마다 목표가 달라서 그에 맞는 손실 함수를 선택해야 한다. - 회귀 문제에서는 MSE, 분류 문제에서는 Cross-Entropy Loss. - 만약 회귀에 클래스 간의 확률 분포 차이를 보여주는 Cross-Entropy Loss를 사용하게 되면 의미에 맞지 않다. 분류 문제에 큰 오차에 더 민감한 MSE를 사용하게 되면 적절하지 않은 예측과 학습이 진행될 것.

### 특성 반영

각 task는 데이터의 특성과 목표가 다르다. 데이터의 특성과 task의 목표에 따라 적절한 손실함수를 사용하면 모델이 성능을 제대로 발휘할 수 있다. - 불균형 데이터의 경우, 가중치가부여된 손실함수를 사요앟여 중요한 클래스에 더 많은 가중치를 부여하여 처리할 수 있다. - 회귀와 분류 작업을 동시에 수행하는 경우에는 각 작업에 맞는 손실 함수를 합쳐서 사용한다.

### 모델 성능 최적화

더 중요하다고 생각하는 부분이나 집중해서 보아야 하는 부분에 더 높은 가중치를 부여하여 손실 함수를 설계하여 특정 오류를 줄이거나 모델의 성능을 원하는 방향으로 최적화가 가능하다.

🎯알려지고 자주 사용하는 Loss Function들만 존재하고 앞으로의 프로젝트나 연구에 사용하는 줄 알았는데, 굳이 기존의 손실 함수를 사용하지 않고 내가 원하는 방향으로 강조하고 싶은 것을 중심으로 직접 설계가 가능하다는 사실을 알게 되었다.

또한, 직접 손실함수를 설계할 때에, 사용할 데이터의 특성과 해결하고자 하는 문제의 종류를 잘 분석하여 그에 맞는 손실함수를 적절하게 설계하여야 한다는 것도 알게 되었다.
